import requests
import os
import json
import base64

# é…ç½®ï¼ˆè¿™äº›ä¼šä» GitHub Secrets è¯»ï¼‰
GITHUB_TOKEN = os.getenv('GH_TOKEN')
REPO_NAME = os.getenv('GITHUB_REPOSITORY')
FILE_PATH = "links.json"

def normalize_url(url):
    """ã€æ–°å¢ã€‘æ ‡å‡†åŒ–é“¾æ¥ï¼šå»æ‰æœ«å°¾æ–œæ å¹¶è½¬å°å†™"""
    return url.strip().rstrip('/').lower()

def check_backlink(url):
    """æ£€æŸ¥å¯¹æ–¹ç½‘ç«™æ˜¯å¦æœ‰æˆ‘çš„å›é“¾"""
    try:
        response = requests.get(url, timeout=15, headers={'User-Agent': 'Mozilla/5.0'})
        if response.status_code == 200:
            # åŒ¹é…ä½ çš„åŸŸå
            return "828111.xyz" in response.text
        return False
    except:
        return False

def run_cleanup():
    if not GITHUB_TOKEN:
        print("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° GH_TOKENï¼Œè¯·æ£€æŸ¥ Secret è®¾ç½®")
        return

    headers = {"Authorization": f"token {GITHUB_TOKEN}", "Accept": "application/vnd.github.v3+json"}
    
    # 1. è·å–æœ€æ–°çš„ links.json
    url = f"https://api.github.com/repos/{REPO_NAME}/contents/{FILE_PATH}"
    res = requests.get(url, headers=headers).json()
    
    if 'content' not in res:
        print(f"âŒ æ— æ³•è·å–æ–‡ä»¶å†…å®¹ï¼ŒGitHub è¿”å›ï¼š{res.get('message', 'æœªçŸ¥é”™è¯¯')}")
        return

    content = base64.b64decode(res['content']).decode('utf-8')
    links = json.loads(content)
    sha = res['sha']

    new_links = []
    seen_urls = set() # ç”¨äºå»é‡
    changes_made = False

    # 2. é€ä¸€å·¡æ£€
    for link in links:
        raw_url = link['url']
        norm_url = normalize_url(raw_url)

        # --- âœ¨ æ–°å¢ï¼šå»é‡é€»è¾‘ ---
        if norm_url in seen_urls:
            print(f"ğŸ—‘ï¸ å‘ç°é‡å¤é¡¹: {link['name']} ({raw_url})ï¼Œå·²è‡ªåŠ¨æ¸…ç†")
            changes_made = True
            continue # è·³è¿‡è¿™ä¸ªé‡å¤çš„
        
        print(f"æ­£åœ¨æ£€æŸ¥: {link['name']}...")
        is_ok = check_backlink(raw_url)
        
        if is_ok:
            if link.get('fail_count', 0) > 0:
                link['fail_count'] = 0 # æ£€æŸ¥é€šè¿‡ï¼Œé‡ç½®å¤±è´¥è®¡æ•°
                changes_made = True
            new_links.append(link)
            seen_urls.add(norm_url) # è®°å½•å·²ç»å¤„ç†è¿‡çš„é“¾æ¥
        else:
            link['fail_count'] = link.get('fail_count', 0) + 1
            print(f"âš ï¸ {link['name']} æ²¡æœåˆ°å›é“¾ (ç¬¬{link['fail_count']}æ¬¡å¤±è´¥)")
            changes_made = True
            
            if link['fail_count'] < 3:
                # å¤±è´¥æ²¡è¶…è¿‡3æ¬¡ï¼Œç•™æ ¡å¯Ÿçœ‹
                new_links.append(link)
                seen_urls.add(norm_url)
            else:
                # è¿ç»­3æ¬¡å¤±è´¥ï¼Œç›´æ¥è¸¢å‡ºåå•
                print(f"âŒ {link['name']} è¿ç»­3æ¬¡å¤±è´¥ï¼Œæ­£å¼å¼€é™¤ï¼")
                continue

    # 3. å¦‚æœæœ‰å˜åŠ¨ï¼ˆæœ‰äººè¢«è¸¢ã€è®¡æ•°æ›´æ–°ã€æˆ–è€…æ¸…ç†äº†é‡å¤é¡¹ï¼‰ï¼Œå†™å›ä»“åº“
    if changes_made:
        new_content = json.dumps(new_links, indent=2, ensure_ascii=False)
        update_data = {
            "message": "ğŸ§¹ å‡Œæ™¨å·¡æ£€ï¼šæ¸…ç†å¤±æ•ˆé“¾æ¥åŠé‡å¤é¡¹",
            "content": base64.b64encode(new_content.encode('utf-8')).decode('utf-8'),
            "sha": sha
        }
        put_res = requests.put(url, headers=headers, json=update_data)
        if put_res.status_code == 200:
            print("âœ… ä»“åº“å·²æ›´æ–°")
        else:
            print(f"âŒ æ›´æ–°å¤±è´¥ï¼š{put_res.json().get('message')}")
    else:
        print("â˜• æ‰€æœ‰è€å“¥éƒ½æŒºé è°±ï¼Œä»Šå¤©æ— éœ€æ¸…ç†")

if __name__ == "__main__":
    run_cleanup()
